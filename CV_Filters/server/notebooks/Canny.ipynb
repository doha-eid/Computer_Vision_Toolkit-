{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "918880e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_12772\\2637389990.py:7: DeprecationWarning: Please use `convolve` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import convolve\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage.filters import convolve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f449e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgbtogray(image):\n",
    "    r,g,b=image[:,:,0],image[:,:,1],image[:,:,2]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5169a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2: apply guassian filter for noise reduction\n",
    "\n",
    "def get_gaussian_kernel(kernal_size, sigma=1):\n",
    "    gaussian_kernal = np.zeros((kernal_size, kernal_size), np.float32)\n",
    "    size = kernal_size//2\n",
    "\n",
    "    for x in range(-size, size+1):\n",
    "        for y in range(-size, size+1):\n",
    "            a = 1/(2*np.pi*(sigma**2))\n",
    "            b = np.exp(-(x**2 + y**2)/(2* sigma**2))\n",
    "            gaussian_kernal[x+size, y+size] = a*b\n",
    "    return gaussian_kernal/gaussian_kernal.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc55881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_filtering(input_image, kernal):\n",
    "    \n",
    "    output_image = []\n",
    "    kernal_size = len(kernal)\n",
    "    kernal_half = kernal_size // 2\n",
    "    rows_count = len(input_image)\n",
    "    columns_count = len(input_image[0])\n",
    "\n",
    "    image_copy = copy.deepcopy(input_image)\n",
    "\n",
    "    # wrap the image in the edge pixels\n",
    "    for i in range(rows_count):\n",
    "        for j in range(kernal_half): \n",
    "            image_copy[i].insert(0, input_image[i][-1-j])\n",
    "            image_copy[i].append(input_image[i][j])\n",
    "    for i in range(kernal_half):\n",
    "        image_copy.append(image_copy[2*i])\n",
    "        image_copy.insert(0, image_copy[-2-2*i].copy())\n",
    "\n",
    "    # apply filtering\n",
    "    new_rows_count = len(image_copy)\n",
    "    new_columns_count = len(image_copy[0])\n",
    "\n",
    "    for i in range(kernal_half, new_rows_count - kernal_half):\n",
    "        output_row = []\n",
    "        for j in range(kernal_half, new_columns_count - kernal_half):\n",
    "            sum = 0\n",
    "            for x in range(len(kernal)):\n",
    "                for y in range(len(kernal)):\n",
    "                    x1 = i + x - kernal_half\n",
    "                    y1 = j + y - kernal_half\n",
    "                    sum += image_copy[x1][y1] * kernal[x][y]\n",
    "            output_row.append(sum)\n",
    "        output_image.append(output_row)\n",
    "\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87ed1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 : gradient estimation\n",
    "\n",
    "def gradient_estimate(image, gradient_estimation_filter_type):\n",
    "\n",
    "    if (gradient_estimation_filter_type==\"sobel\"):\n",
    "        Mx = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], np.float32)\n",
    "        My = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]], np.float32)\n",
    "    elif (gradient_estimation_filter_type==\"prewitt\"):\n",
    "        Mx = np.array([[-1, 0, 1], [-1, 0, 1], [-1, 0, 1]], np.float32)\n",
    "        My = np.array([[1, 1, 1], [0, 0, 0], [-1, -1, -1]], np.float32)\n",
    "    else:\n",
    "        Mx = np.array([[0, 1], [-1, 0]], np.float32)\n",
    "        My = np.array([[1, 0], [0, -1]], np.float32)\n",
    "\n",
    "    X = apply_filtering(image, Mx)\n",
    "    Y = apply_filtering(image, My)\n",
    "\n",
    "    G = np.hypot(X, Y)\n",
    "    G = G / G.max() * 255\n",
    "    theta = np.arctan2(Y, X)\n",
    "\n",
    "    return (G, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c114dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 : non-maxima suppression to thin out the edges\n",
    "\n",
    "def non_maxima_suppression(image, gradient_direction):\n",
    "    rows_count = len(image)\n",
    "    columns_count = len(image[0])\n",
    "\n",
    "    output_image = np.zeros((rows_count, columns_count), dtype=np.int32)\n",
    "    theta = gradient_direction * 180. / np.pi\n",
    "    theta[theta < 0] += 180\n",
    "\n",
    "    \n",
    "    for i in range(1, rows_count-1):\n",
    "        for j in range(1, columns_count-1):\n",
    "            next = 255\n",
    "            previous = 255\n",
    "            if (0 <= theta[i,j] < 22.5) or (157.5 <= theta[i,j] <= 180):\n",
    "                next = image[i, j+1]\n",
    "                previous = image[i, j-1]\n",
    "            elif (22.5 <= theta[i,j] < 67.5):\n",
    "                next = image[i+1, j-1]\n",
    "                previous = image[i-1, j+1]\n",
    "            elif (67.5 <= theta[i,j] < 112.5):\n",
    "                next = image[i+1, j]\n",
    "                previous = image[i-1, j]\n",
    "            elif (112.5 <= theta[i,j] < 157.5):\n",
    "                next = image[i-1, j-1]\n",
    "                previous = image[i+1, j+1]\n",
    "\n",
    "            if (image[i,j] >= next) and (image[i,j] >= previous):\n",
    "                output_image[i,j] = image[i,j]\n",
    "            else:\n",
    "                output_image[i,j] = 0\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "335980ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_threshold(image, low_threshold_ratio, high_threshold_ratio):\n",
    "    \n",
    "    high_threshold = image.max() * high_threshold_ratio;\n",
    "    low_threshold = high_threshold * low_threshold_ratio;\n",
    "    \n",
    "    rows_count = len(image)\n",
    "    columns_count = len(image[0])\n",
    "    output_image = np.zeros((rows_count, columns_count), dtype=np.int32)\n",
    "    \n",
    "    weak = np.int32(25)\n",
    "    strong = np.int32(255)\n",
    "\n",
    "    strong_i = []\n",
    "    strong_j = []\n",
    "    weak_i = [] \n",
    "    weak_j = []\n",
    "    for i in range (len(image)):\n",
    "        for j in range (len(image[0])):\n",
    "            if (image[i,j]>=high_threshold):\n",
    "                strong_i.append(i)\n",
    "                strong_j.append(j)\n",
    "            if ((image[i,j] <= high_threshold) & (image[i,j] >= low_threshold)):\n",
    "                weak_i.append(i)\n",
    "                weak_j.append(j)\n",
    "    strong_i = np.array(strong_i)\n",
    "    strong_j = np.array(strong_j)\n",
    "    weak_i = np.array(weak_i)\n",
    "    weak_j = np.array(weak_j)\n",
    "    \n",
    "    output_image[strong_i, strong_j] = strong\n",
    "    output_image[weak_i, weak_j] = weak\n",
    "\n",
    "\n",
    "    \n",
    "    return (output_image, weak, strong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f83fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hysteresis_edge_track(image, weak, strong=255):\n",
    "    rows_count = len(image)\n",
    "    columns_count = len(image[0]) \n",
    "    for i in range(1, rows_count-1):\n",
    "        for j in range(1, columns_count-1):\n",
    "            if (image[i,j] == weak):\n",
    "                if ((image[i+1, j-1] == strong) or (image[i+1, j] == strong) or (image[i+1, j+1] == strong)\n",
    "                    or (image[i, j-1] == strong) or (image[i, j+1] == strong)\n",
    "                    or (image[i-1, j-1] == strong) or (image[i-1, j] == strong) or (image[i-1, j+1] == strong)):\n",
    "                    image[i, j] = strong\n",
    "                else:\n",
    "                    image[i, j] = 0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0fbad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\SBME\\3rd Year\\Computer Vision\\Task1_cv\\server\\notebooks\\Canny.ipynb Cell 9\u001b[0m in \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(\u001b[39m\"\u001b[39m\u001b[39m../server/static/assests/image1.jpg\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# step 1 : convert image to gray scale\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m gray_scaled_image \u001b[39m=\u001b[39m rgbtogray(image)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# step 2 : apply gaussian kernal to filter noise\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m kernal \u001b[39m=\u001b[39m get_gaussian_kernel(kernal_size)\n",
      "\u001b[1;32md:\\SBME\\3rd Year\\Computer Vision\\Task1_cv\\server\\notebooks\\Canny.ipynb Cell 9\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrgbtogray\u001b[39m(image):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     r,g,b\u001b[39m=\u001b[39mimage[:,:,\u001b[39m0\u001b[39;49m],image[:,:,\u001b[39m1\u001b[39m],image[:,:,\u001b[39m2\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     gray \u001b[39m=\u001b[39m \u001b[39m0.2989\u001b[39m \u001b[39m*\u001b[39m r \u001b[39m+\u001b[39m \u001b[39m0.5870\u001b[39m \u001b[39m*\u001b[39m g \u001b[39m+\u001b[39m \u001b[39m0.1140\u001b[39m \u001b[39m*\u001b[39m b\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBME/3rd%20Year/Computer%20Vision/Task1_cv/server/notebooks/Canny.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m gray\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "kernal_size = 3\n",
    "low_threshold_ratio = 0.05\n",
    "high_threshold_ratio = 0.09\n",
    "gradient_estimation_filter_type = \"sobel\"\n",
    "# load image\n",
    "image = cv2.imread(\"../server/static/assests/image1.jpg\")\n",
    "\n",
    "# step 1 : convert image to gray scale\n",
    "gray_scaled_image = rgbtogray(image)\n",
    "\n",
    "# step 2 : apply gaussian kernal to filter noise\n",
    "kernal = get_gaussian_kernel(kernal_size)\n",
    "image_without_noise = apply_filtering(gray_scaled_image.tolist(), kernal)\n",
    "\n",
    "# step 3 : gradient estimation\n",
    "assert (gradient_estimation_filter_type in [\"sobel\", \"prewitt\", \"robert\"]), \"gradient estimation filter type should be [\\\"prewitt\\\", \\\"sobel\\\", \\\"robert\\\"]\"\n",
    "G, theta = gradient_estimate(image_without_noise, gradient_estimation_filter_type)\n",
    "\n",
    "# step 4 : non maxima suppression\n",
    "image_with_thin_edges = non_maxima_suppression(G, theta)\n",
    "\n",
    "# step 5 : double threshold\n",
    "final_image, weak, strong = double_threshold(image_with_thin_edges, low_threshold_ratio, high_threshold_ratio)\n",
    "\n",
    "# edge tracking with hysteresis\n",
    "img = hysteresis_edge_track(final_image, weak, strong=255)\n",
    "plt.imshow(np.array(img),cmap=\"gray\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "213524bb45a1aeaf737b1d8c77d7b8db5d425938d9dffc5f4bc6fe6dd3324700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
